{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Java Metrics Analyzer (No Radon)\n",
    "\n",
    "This notebook reads Java file paths from `labels.csv`, parses the Java code, and calculates:\n",
    "- Methods per class\n",
    "- Parameters per method\n",
    "- Cyclomatic complexity (custom logic)\n",
    "- Comment density (excluding commented-out code)\n",
    "- LOC per method\n",
    "- Number of public methods\n",
    "- halsted volume\n",
    "\n",
    "It saves results in `metrics.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import javalang\n",
    "import os\n",
    "import re\n",
    "\n",
    "def read_java_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0a2af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "\n",
    "def calculate_halstead_volume(code):\n",
    "    operators = set([\n",
    "        '+', '-', '*', '/', '%', '++', '--', '==', '!=', '>', '<', '>=', '<=', \n",
    "        '&&', '||', '!', '&', '|', '^', '~', '<<', '>>', '=', '+=', '-=', '*=', '/=',\n",
    "        '%=', '&=', '|=', '^=', '<<=', '>>='\n",
    "    ])\n",
    "    \n",
    "    # Regex for Java operators and operands\n",
    "    operator_pattern = r'(\\+|\\-|\\*|\\/|\\%|\\+\\+|\\-\\-|\\=\\=|\\!\\=|\\>\\=|\\<\\=|\\>|\\<|\\&\\&|\\|\\||\\!|\\=|\\+=|\\-=|\\*=|/=|%=|&=|\\|=|\\^=|<<=|>>=|&|\\||\\^|~|<<|>>)'\n",
    "    operand_pattern = r'\\b[_a-zA-Z][_a-zA-Z0-9]*\\b'\n",
    "\n",
    "    operator_matches = re.findall(operator_pattern, code)\n",
    "    operand_matches = re.findall(operand_pattern, code)\n",
    "\n",
    "    n1 = len(set(operator_matches))\n",
    "    n2 = len(set(operand_matches))\n",
    "    N1 = len(operator_matches)\n",
    "    N2 = len(operand_matches)\n",
    "\n",
    "    n = n1 + n2\n",
    "    N = N1 + N2\n",
    "\n",
    "    if n == 0:\n",
    "        return 0.0  # Avoid log(0)\n",
    "\n",
    "    volume = N * math.log2(max(n, 1))\n",
    "    return volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nesting_depth(statements, current_depth=1):\n",
    "    max_depth = current_depth\n",
    "\n",
    "    if not statements:\n",
    "        return max_depth\n",
    "\n",
    "    if not isinstance(statements, list):\n",
    "        statements = [statements]\n",
    "\n",
    "    for stmt in statements:\n",
    "        if hasattr(stmt, 'body'):\n",
    "            body = stmt.body\n",
    "            if isinstance(body, list):\n",
    "                depth = get_nesting_depth(body, current_depth + 1)\n",
    "            else:\n",
    "                depth = get_nesting_depth([body], current_depth + 1)\n",
    "            max_depth = max(max_depth, depth)\n",
    "\n",
    "        elif hasattr(stmt, 'then_statement'):\n",
    "            then_stmt = stmt.then_statement\n",
    "            if isinstance(then_stmt, list):\n",
    "                depth = get_nesting_depth(then_stmt, current_depth + 1)\n",
    "            else:\n",
    "                depth = get_nesting_depth([then_stmt], current_depth + 1)\n",
    "            max_depth = max(max_depth, depth)\n",
    "\n",
    "        elif hasattr(stmt, 'block'):\n",
    "            block = stmt.block\n",
    "            if hasattr(block, 'statements'):\n",
    "                depth = get_nesting_depth(block.statements, current_depth + 1)\n",
    "                max_depth = max(max_depth, depth)\n",
    "\n",
    "    return max_depth\n",
    "\n",
    "\n",
    "def calculate_metrics(code):\n",
    "    metrics = {\n",
    "        'methods_per_class': 0,\n",
    "        'params_per_method': 0,\n",
    "        'cyclomatic_complexity': 1,  # base = 1\n",
    "        'comment_density': 0,\n",
    "        'loc_per_method': 0,\n",
    "        'public_methods': 0,\n",
    "        'nesting_depth': 0,\n",
    "        'halstead_volume': 0,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        tree = javalang.parse.parse(code)\n",
    "    except:\n",
    "        return metrics\n",
    "\n",
    "    total_classes = 0\n",
    "    total_methods = 0\n",
    "    total_params = 0\n",
    "    total_locs = 0\n",
    "    public_method_count = 0\n",
    "\n",
    "    # Estimate method bodies from start to end lines\n",
    "    lines = code.splitlines()\n",
    "\n",
    "    for path, node in tree:\n",
    "        if isinstance(node, javalang.tree.ClassDeclaration):\n",
    "            total_classes += 1\n",
    "            methods = node.methods\n",
    "            total_methods += len(methods)\n",
    "\n",
    "            for m in methods:\n",
    "                # Parameters\n",
    "                total_params += len(m.parameters)\n",
    "\n",
    "                # Public method count\n",
    "                if 'public' in m.modifiers:\n",
    "                    public_method_count += 1\n",
    "\n",
    "                # Nesting depth\n",
    "                if m.body:\n",
    "                    metrics['nesting_depth'] = max(metrics['nesting_depth'], get_nesting_depth(m.body))\n",
    "\n",
    "                # LOC per method: estimate start and end lines\n",
    "                method_start = m.position.line if hasattr(m, 'position') and m.position else None\n",
    "                method_end = None\n",
    "                if m.body and isinstance(m.body, list):\n",
    "                    body_lines = [stmt.position.line for stmt in m.body if hasattr(stmt, 'position') and stmt.position]\n",
    "                    if body_lines:\n",
    "                        method_end = max(body_lines)\n",
    "                if method_start and method_end:\n",
    "                    method_lines = lines[method_start - 1 : method_end]\n",
    "                    total_locs += len(method_lines)\n",
    "\n",
    "    # Cyclomatic Complexity (basic estimation)\n",
    "    control_keywords = ['if', 'for', 'while', 'case', 'catch', '&&', r'\\|\\|', r'\\?']\n",
    "    for keyword in control_keywords:\n",
    "        pattern = rf'\\b{keyword}\\b'\n",
    "        matches = re.findall(pattern, code)\n",
    "        metrics['cyclomatic_complexity'] += len(matches)\n",
    "\n",
    "    # Comment Density\n",
    "    comment_lines = 0\n",
    "    code_lines = 0\n",
    "    in_block_comment = False\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "        if in_block_comment:\n",
    "            comment_lines += 1\n",
    "            if '*/' in stripped:\n",
    "                in_block_comment = False\n",
    "        elif stripped.startswith('//'):\n",
    "            comment_lines += 1\n",
    "        elif '/*' in stripped:\n",
    "            comment_lines += 1\n",
    "            if '*/' not in stripped:\n",
    "                in_block_comment = True\n",
    "        elif stripped and not stripped.startswith('//') and not in_block_comment:\n",
    "            code_lines += 1\n",
    "\n",
    "    total_lines = comment_lines + code_lines\n",
    "    metrics['comment_density'] = comment_lines / total_lines if total_lines > 0 else 0\n",
    "\n",
    "    # Final calculations\n",
    "    metrics['methods_per_class'] = total_methods / total_classes if total_classes > 0 else 0\n",
    "    metrics['params_per_method'] = total_params / total_methods if total_methods > 0 else 0\n",
    "    metrics['loc_per_method'] = total_locs / total_methods if total_methods > 0 else 0\n",
    "    metrics['public_methods'] = public_method_count\n",
    "    metrics['halstead_volume'] = calculate_halstead_volume(code)\n",
    "\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Normalized metrics saved to 'output.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def normalize(value, min_val, max_val):\n",
    "    if max_val == min_val:\n",
    "        return 5.5  # Neutral value when no variation\n",
    "    scaled = 1 + 9 * ((value - min_val) / (max_val - min_val))\n",
    "    return round(max(1.0, min(10.0, scaled)), 2)\n",
    "\n",
    "# Step 1: Read input.csv\n",
    "df = pd.read_csv(\"Ollama_output.csv\")\n",
    "\n",
    "# Step 2: Calculate metrics\n",
    "metrics_list = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    example = row['Example']\n",
    "    code = row['Generated Java Code']\n",
    "\n",
    "    # Skip if code is empty or only whitespace or NaN\n",
    "    if pd.isna(code) or not str(code).strip():\n",
    "        print(f\"⚠️ Skipping Example {example} (no Java code)\")\n",
    "        continue\n",
    "\n",
    "    # Call your metric calculation function here\n",
    "    metrics = calculate_metrics(code)\n",
    "\n",
    "    # Add example number to the metrics dict at the beginning\n",
    "    metrics_with_example = {'Example': example}\n",
    "    metrics_with_example.update(metrics)\n",
    "\n",
    "    metrics_list.append(metrics_with_example)\n",
    "\n",
    "# Step 3: Create DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "# Step 4: Normalize each metric (except Example)\n",
    "for column in metrics_df.columns:\n",
    "    if column == 'Example':\n",
    "        continue\n",
    "    min_val = metrics_df[column].min()\n",
    "    max_val = metrics_df[column].max()\n",
    "    metrics_df[column] = metrics_df[column].apply(lambda x: normalize(x, min_val, max_val))\n",
    "    #metrics_df[column] = metrics_df[column]\n",
    "\n",
    "# Step 5: Ensure 'Example' is first column\n",
    "columns_order = ['Example'] + [col for col in metrics_df.columns if col != 'Example']\n",
    "metrics_df = metrics_df[columns_order]\n",
    "\n",
    "# Step 6: Save metrics to output.csv\n",
    "metrics_df.to_csv(\"reports/llma3.2_Matrics.csv\", index=False)\n",
    "print(\"✅ Normalized metrics saved to 'output.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bdf748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05bf9998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned Java code saved to 'cleaned_input.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_java_code(code):\n",
    "    if pd.isna(code):\n",
    "        return ''\n",
    "    \n",
    "    code = str(code).strip()\n",
    "    \n",
    "    # Remove ```java at the start\n",
    "    if code.startswith('```java'):\n",
    "        code = code[len('```java'):].strip()\n",
    "    \n",
    "    # Remove ``` at the end\n",
    "    if code.endswith('```'):\n",
    "        code = code[:-3].strip()\n",
    "    \n",
    "    # Also remove any escaped quotes if needed\n",
    "    code = code.replace('\\\"\\\"', '\"').replace(\"''\", \"'\")\n",
    "    \n",
    "    return code\n",
    "\n",
    "# Example usage:\n",
    "df = pd.read_csv('Gemini_output200.csv')\n",
    "\n",
    "# Apply the cleaning function\n",
    "df['Generated Java Code'] = df['Generated Java Code'].apply(clean_java_code)\n",
    "\n",
    "# Optionally save the cleaned file to check it\n",
    "df.to_csv('cleinput.csv', index=False)\n",
    "\n",
    "print(\"✅ Cleaned Java code saved to 'cleaned_input.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
